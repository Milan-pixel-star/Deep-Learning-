{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1717747869932,"user":{"displayName":"Milan Kachhawaha","userId":"12924651672798112385"},"user_tz":-330},"id":"PaLuVUg_qmWN"},"outputs":[],"source":["# sentiment analysis RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZUZ24IYwGMS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1717747934266,"user":{"displayName":"Milan Kachhawaha","userId":"12924651672798112385"},"user_tz":-330},"id":"p1I8A-U4vq8u"},"outputs":[],"source":["from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, LSTM, GRU, Bidirectional\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.datasets import imdb\n","import numpy as np"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5329,"status":"ok","timestamp":1717748039454,"user":{"displayName":"Milan Kachhawaha","userId":"12924651672798112385"},"user_tz":-330},"id":"epO7CfRHwV5P","outputId":"edec63b6-e643-421a-8d73-15452bb83530"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"]}],"source":["# getting reviews with words that come under 5000\n","# most occuring words int the entire\n","# corps of textual review data\n","\n","vocab_size = 5000\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n","\n","print(X_train[0])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717748579454,"user":{"displayName":"Milan Kachhawaha","userId":"12924651672798112385"},"user_tz":-330},"id":"ezkLyqp5wp7G","outputId":"c0e3ffce-5f57-4e49-e25d-e4a6f82c21e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["['the', 'as', 'you', 'with', 'out', 'themselves', 'powerful', 'lets', 'loves', 'their', 'becomes', 'reaching', 'had', 'journalist', 'of', 'lot', 'from', 'anyone', 'to', 'have', 'after', 'out', 'atmosphere', 'never', 'more', 'room', 'and', 'it', 'so', 'heart', 'shows', 'to', 'years', 'of', 'every', 'never', 'going', 'and', 'help', 'moments', 'or', 'of', 'every', 'chest', 'visual', 'movie', 'except', 'her', 'was', 'several', 'of', 'enough', 'more', 'with', 'is', 'now', 'current', 'film', 'as', 'you', 'of', 'mine', 'potentially', 'unfortunately', 'of', 'you', 'than', 'him', 'that', 'with', 'out', 'themselves', 'her', 'get', 'for', 'was', 'camp', 'of', 'you', 'movie', 'sometimes', 'movie', 'that', 'with', 'scary', 'but', 'and', 'to', 'story', 'wonderful', 'that', 'in', 'seeing', 'in', 'character', 'to', 'of', '70s', 'and', 'with', 'heart', 'had', 'shadows', 'they', 'of', 'here', 'that', 'with', 'her', 'serious', 'to', 'have', 'does', 'when', 'from', 'why', 'what', 'have', 'critics', 'they', 'is', 'you', 'that', \"isn't\", 'one', 'will', 'very', 'to', 'as', 'itself', 'with', 'other', 'and', 'in', 'of', 'seen', 'over', 'and', 'for', 'anyone', 'of', 'and', 'br', \"show's\", 'to', 'whether', 'from', 'than', 'out', 'themselves', 'history', 'he', 'name', 'half', 'some', 'br', 'of', 'and', 'odd', 'was', 'two', 'most', 'of', 'mean', 'for', '1', 'any', 'an', 'boat', 'she', 'he', 'should', 'is', 'thought', 'and', 'but', 'of', 'script', 'you', 'not', 'while', 'history', 'he', 'heart', 'to', 'real', 'at', 'and', 'but', 'when', 'from', 'one', 'bit', 'then', 'have', 'two', 'of', 'script', 'their', 'with', 'her', 'nobody', 'most', 'that', 'with', \"wasn't\", 'to', 'with', 'armed', 'acting', 'watch', 'an', 'for', 'with', 'and', 'film', 'want', 'an']\n"]}],"source":["# getting all the words from word_index dictionary\n","word_idx = imdb.get_word_index()\n","\n","# originally the index number of a value and not a key\n","# hence converting the index as a key and the words as avalues\n","word_idx = {i:word for word,i in word_idx.items()}\n","\n","# again printing the reviews\n","print([word_idx[i] for i in X_train[0]])"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1018,"status":"ok","timestamp":1717748518221,"user":{"displayName":"Milan Kachhawaha","userId":"12924651672798112385"},"user_tz":-330},"id":"Etsc9y5syAgz","outputId":"9b2d3918-b82c-4b9a-91e4-fdb5fd67e346"},"outputs":[{"name":"stdout","output_type":"stream","text":["Max length of a review::  2697\n","Min length of a review::  70\n"]}],"source":["# get the minimum and maimum length of the reviews\n","print(\"Max length of a review:: \", len(max(X_train+X_test, key=len)))\n","print(\"Min length of a review:: \", len(min(X_train+X_test, key=len)))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":812,"status":"ok","timestamp":1717748743054,"user":{"displayName":"Milan Kachhawaha","userId":"12924651672798112385"},"user_tz":-330},"id":"-zVsCFFQykNs"},"outputs":[],"source":["from tensorflow.keras.preprocessing import sequence\n","\n","# keeping a fixed length of all reviews\n","max_len =400\n","\n","X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n","X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n","\n","X_valid, y_valid = X_train[:64], y_train[:64]\n","X_train, y_train = X_train[64:], y_train[64:]"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284926,"status":"ok","timestamp":1717749754240,"user":{"displayName":"Milan Kachhawaha","userId":"12924651672798112385"},"user_tz":-330},"id":"RqVZzrSWzYJM","outputId":"33b0a1d5-da2f-45cb-c0bd-fc9799156b20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Simple_RNN\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 400, 32)           160000    \n","                                                                 \n"," simple_rnn_1 (SimpleRNN)    (None, 32)                2080      \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 162113 (633.25 KB)\n","Trainable params: 162113 (633.25 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/5\n","390/390 [==============================] - 46s 115ms/step - loss: 0.5866 - accuracy: 0.6845 - val_loss: 0.4606 - val_accuracy: 0.8281\n","Epoch 2/5\n","390/390 [==============================] - 43s 110ms/step - loss: 0.4091 - accuracy: 0.8227 - val_loss: 0.3833 - val_accuracy: 0.8594\n","Epoch 3/5\n","390/390 [==============================] - 42s 107ms/step - loss: 0.3299 - accuracy: 0.8674 - val_loss: 1.0039 - val_accuracy: 0.5781\n","Epoch 4/5\n","390/390 [==============================] - 42s 106ms/step - loss: 0.2644 - accuracy: 0.8987 - val_loss: 0.3851 - val_accuracy: 0.8438\n","Epoch 5/5\n","390/390 [==============================] - 40s 104ms/step - loss: 0.2168 - accuracy: 0.9151 - val_loss: 0.3763 - val_accuracy: 0.8594\n","\n","Simple_RNN Score ---\u003e  [0.42747950553894043, 0.8333600163459778]\n"]}],"source":["# fixing every word's embedding size to be 32\n","embed_size = 32\n","\n","# creating a RNN model\n","RNN_model = Sequential(name=\"Simple_RNN\")\n","RNN_model.add(Embedding(vocab_size,\n","                        embed_size,\n","                        input_length=(max_len)))\n","\n","# in case of a stacked(more than one layer of RNN)\n","# use return_sequential=True\n","RNN_model.add(SimpleRNN(32,\n","                        activation='tanh',\n","                        return_sequences=False))\n","RNN_model.add(Dense(1, activation='sigmoid'))\n","\n","# printing model summary\n","print(RNN_model.summary())\n","\n","# compeling model\n","RNN_model.compile(\n","    loss='binary_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy'])\n","\n","# fitting model # training the model\n","history = RNN_model.fit(X_train, y_train,\n","              batch_size=64,\n","              epochs=5,\n","              verbose=1,\n","              validation_data=(X_valid, y_valid))\n","\n","print()\n","print(\"Simple_RNN Score ---\u003e \", RNN_model.evaluate(X_test, y_test, verbose=0))"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":470618,"status":"ok","timestamp":1717751077054,"user":{"displayName":"Milan Kachhawaha","userId":"12924651672798112385"},"user_tz":-330},"id":"cgEhSNPP1aCP","outputId":"8302829b-7b21-4bca-af44-62960836f2a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"GRU_Model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, 400, 32)           160000    \n","                                                                 \n"," gru_1 (GRU)                 (None, 32)                6336      \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 166369 (649.88 KB)\n","Trainable params: 166369 (649.88 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/5\n","390/390 [==============================] - 84s 208ms/step - loss: 0.4420 - accuracy: 0.7810 - val_loss: 0.2449 - val_accuracy: 0.9062\n","Epoch 2/5\n","390/390 [==============================] - 82s 211ms/step - loss: 0.2724 - accuracy: 0.8927 - val_loss: 0.2861 - val_accuracy: 0.9062\n","Epoch 3/5\n","390/390 [==============================] - 78s 201ms/step - loss: 0.2227 - accuracy: 0.9138 - val_loss: 0.2493 - val_accuracy: 0.8906\n","Epoch 4/5\n","390/390 [==============================] - 83s 213ms/step - loss: 0.1959 - accuracy: 0.9256 - val_loss: 0.2834 - val_accuracy: 0.9062\n","Epoch 5/5\n","390/390 [==============================] - 83s 213ms/step - loss: 0.1643 - accuracy: 0.9385 - val_loss: 0.2588 - val_accuracy: 0.9375\n","\n","GRU Score ---\u003e  [0.33004817366600037, 0.8781200051307678]\n"]}],"source":["# Defining GRU model\n","gru_model = Sequential(name=\"GRU_Model\")\n","gru_model.add(Embedding(vocab_size,\n","                        embed_size,\n","                        input_length=(max_len)))\n","\n","gru_model.add(GRU(32,\n","                  activation='tanh',\n","                  return_sequences=False))\n","gru_model.add(Dense(1, activation='sigmoid'))\n","\n","# printing model summary\n","print(gru_model.summary())\n","\n","gru_model.compile(\n","    loss='binary_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy'])\n","\n","# fitting model # training the GRU model\n","history = gru_model.fit(X_train, y_train,\n","              batch_size=64,\n","              epochs=5,\n","              verbose=1,\n","              validation_data=(X_valid, y_valid))\n","\n","print()\n","print(\"GRU Score ---\u003e \", gru_model.evaluate(X_test, y_test, verbose=0))"]},{"cell_type":"markdown","metadata":{"id":"nquI3H6D7dAg"},"source":["Bidirectional LSTMS are a derivative of a treaditional LSTMS. Here, two LSEMs are used to capture the forward and backward sequences of the input. This helps in capturing the context better than normal LSTM."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ihmiWAu7cki"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Vopf43A23VuQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"LSTM_Model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_4 (Embedding)     (None, 400, 32)           160000    \n","                                                                 \n"," lstm (LSTM)                 (None, 128)               82432     \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 242561 (947.50 KB)\n","Trainable params: 242561 (947.50 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/5\n","390/390 [==============================] - 314s 797ms/step - loss: 0.4932 - accuracy: 0.7512 - val_loss: 0.2917 - val_accuracy: 0.9062\n","Epoch 2/5\n","390/390 [==============================] - 307s 787ms/step - loss: 0.3083 - accuracy: 0.8752 - val_loss: 0.2473 - val_accuracy: 0.9062\n","Epoch 3/5\n","390/390 [==============================] - 303s 778ms/step - loss: 0.2577 - accuracy: 0.9005 - val_loss: 0.3585 - val_accuracy: 0.8438\n","Epoch 4/5\n","390/390 [==============================] - 309s 793ms/step - loss: 0.2455 - accuracy: 0.9042 - val_loss: 0.3013 - val_accuracy: 0.8281\n","Epoch 5/5\n","390/390 [==============================] - 302s 775ms/step - loss: 0.2036 - accuracy: 0.9214 - val_loss: 0.2885 - val_accuracy: 0.8594\n","\n","LSTM Score ---\u003e  [0.36020398139953613, 0.866919994354248]\n"]}],"source":["# Defining LSTM model\n","lstm_model = Sequential(name=\"LSTM_Model\")\n","lstm_model.add(Embedding(vocab_size,\n","                        embed_size,\n","                        input_length=(max_len)))\n","lstm_model.add(LSTM(128,\n","                  activation='tanh',\n","                  return_sequences=False))\n","lstm_model.add(Dense(1, activation='sigmoid'))\n","\n","# printing model summary\n","print(lstm_model.summary())\n","\n","#compile the model\n","lstm_model.compile(\n","    loss='binary_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy'])\n","\n","# fitting model # training the LSTM\n","history3 = lstm_model.fit(X_train, y_train,\n","              batch_size=64,\n","              epochs=5,\n","              verbose=1,\n","              validation_data=(X_valid, y_valid))\n","\n","print()\n","print(\"LSTM Score ---\u003e \", lstm_model.evaluate(X_test, y_test, verbose=0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMhji59e50RI"},"outputs":[],"source":["# Defining Bidirectional LSTM Model\n","bi_lstm_model = Sequential(name=\"Bi_LSTM_Model\")\n","bi_lstm_model.add(Embedding(vocab_size,\n","                        embed_size,\n","                        input_length=(max_len)))\n","bi_lstm_model.add(Bidirectional(LSTM(128,\n","                  activation='tanh',\n","                  input_length=(max_len))))\n","\n","bi_lstm_model.add(Dense(1, activation='sigmoid'))\n","\n","# printing model summary\n","print(bi_lstm_model.summary())\n","\n","#compile the model\n","bi_lstm_model.compile(\n","    loss='binary_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy'])\n","\n","# fitting model # training the LSTM\n","history4 = bi_lstm_model.fit(X_train, y_train,\n","              batch_size=64,\n","              epochs=5,\n","              verbose=1,\n","              validation_data=(X_valid, y_valid))\n","\n","print()\n","print(\"LSTM Score ---\u003e \",bi_lstm_model.evaluate(X_test, y_test, verbose=0))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOyWFMmCww+m8zlB/oVrNIm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}